{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31m404.html\u001b[m\u001b[m          doc.html          \u001b[1m\u001b[31mindex.html\u001b[m\u001b[m        \u001b[1m\u001b[31monelist.html\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[31mcomparelists.html\u001b[m\u001b[m hg38_gallery.html mm10_gallery.html stat.html\r\n"
     ]
    }
   ],
   "source": [
    "!ls templates/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replacing all hard-coded urls with relative links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "genelist_str = '<td><a href=\"http://lisa.cistrome.org/gallery/13_down.txt\">down</a><span> & </span><a href=http://lisa.cistrome.org/gallery/13_up.txt>up</a></td>'\n",
    "gallery_str = '<td><div class=\"col\"><a class=\"\" href=\"http://lisa.cistrome.org/new_gallery/20_combined.html\">Combined</a></div></td>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = 'mm10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<td><a href=\"{{ url_for('get_gallery_genelist', species='mm10', filename='13_down.txt') }}\">down</a><span> & </span><a href=\"{{ url_for('get_gallery_genelist', species='mm10', filename='13_up.txt') }}\">up</a></td>\n"
     ]
    }
   ],
   "source": [
    "GENELIST_PARSER = re.compile('\"*http://lisa.cistrome.org/gallery/(\\d+_(up|down).txt)\"*')\n",
    "\n",
    "def replace_genelists(html_line, species):\n",
    "    return re.sub(GENELIST_PARSER, \n",
    "        \"\\\"{{ url_for('get_gallery_genelist', species='\" + species + \"', filename='\\\\1') }}\\\"\", \n",
    "        html_line)\n",
    "\n",
    "print(replace_genelists(test_str, 'mm10'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<td><div class=\"col\"><a class=\"\" href=\"{{ url_for('get_gallery_example', species='mm10', filename ='20_combined.html')}}\">Combined</a></div></td>\n"
     ]
    }
   ],
   "source": [
    "GALLERY_PARSER = re.compile('\"*http://lisa.cistrome.org/new_gallery[_m]*/(\\d+_combined.html)\"*')\n",
    "\n",
    "def replace_examples(html_line, species):\n",
    "    return re.sub(GALLERY_PARSER, \n",
    "        \"\\\"{{ url_for('get_gallery_example', species='\" + species + \"', filename ='\\\\1') }}\\\"\",\n",
    "        html_line)\n",
    "\n",
    "print(replace_examples(gallery_str, 'mm10'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<td><div class=\"col\"><a class=\"\" href=\"{{ url_for('get_gallery_example', species='mm10', filename ='20_combined.html')}}\">Combined</a></div></td>\n"
     ]
    }
   ],
   "source": [
    "print(replace_examples(replace_genelists(gallery_str, 'mm10'), 'mm10'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('templates/new_gallery_mm.html', 'r') as html:\n",
    "    with open('templates/fixed_gallery.html', 'w') as fixed_html:\n",
    "        for line in html:\n",
    "            print(\n",
    "                replace_examples(replace_genelists(line, 'mm10'), 'mm10'),\n",
    "                file = fixed_html\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting hg38 and mm10 genelists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "genelist_match = re.compile(r'filename *= *\\'(\\d+_(up|down).txt)\\'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_str = \"<td><a href=\\\"{{ url_for('get_gallery_genelist', species='hg38', filename='4_down.txt') }}\\\">down</a><span> & </span><a href=\\\"{{ url_for('get_gallery_genelist', species='hg38', filename='4_up.txt') }}\\\">up</a></td>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13_down.txt\n",
      "13_up.txt\n",
      "20_down.txt\n",
      "20_up.txt\n",
      "37_down.txt\n",
      "37_up.txt\n",
      "58_down.txt\n",
      "58_up.txt\n",
      "59_down.txt\n",
      "59_up.txt\n",
      "60_down.txt\n",
      "60_up.txt\n",
      "66_down.txt\n",
      "66_up.txt\n",
      "89_down.txt\n",
      "89_up.txt\n",
      "90_down.txt\n",
      "90_up.txt\n",
      "135_down.txt\n",
      "135_up.txt\n",
      "152_down.txt\n",
      "152_up.txt\n",
      "154_down.txt\n",
      "154_up.txt\n",
      "155_down.txt\n",
      "155_up.txt\n",
      "156_down.txt\n",
      "156_up.txt\n",
      "157_down.txt\n",
      "157_up.txt\n",
      "158_down.txt\n",
      "158_up.txt\n",
      "159_down.txt\n",
      "159_up.txt\n",
      "160_down.txt\n",
      "160_up.txt\n",
      "161_down.txt\n",
      "161_up.txt\n",
      "162_down.txt\n",
      "162_up.txt\n",
      "163_down.txt\n",
      "163_up.txt\n",
      "172_down.txt\n",
      "172_up.txt\n",
      "173_down.txt\n",
      "173_up.txt\n",
      "174_down.txt\n",
      "174_up.txt\n",
      "175_down.txt\n",
      "175_up.txt\n",
      "176_down.txt\n",
      "176_up.txt\n",
      "177_down.txt\n",
      "177_up.txt\n",
      "178_down.txt\n",
      "178_up.txt\n",
      "180_down.txt\n",
      "180_up.txt\n",
      "181_down.txt\n",
      "181_up.txt\n",
      "182_down.txt\n",
      "182_up.txt\n",
      "183_down.txt\n",
      "183_up.txt\n",
      "187_down.txt\n",
      "187_up.txt\n",
      "189_down.txt\n",
      "189_up.txt\n",
      "199_down.txt\n",
      "199_up.txt\n",
      "220_down.txt\n",
      "220_up.txt\n",
      "222_down.txt\n",
      "222_up.txt\n",
      "234_down.txt\n",
      "234_up.txt\n",
      "235_down.txt\n",
      "235_up.txt\n",
      "236_down.txt\n",
      "236_up.txt\n",
      "237_down.txt\n",
      "237_up.txt\n",
      "238_down.txt\n",
      "238_up.txt\n",
      "239_down.txt\n",
      "239_up.txt\n",
      "250_down.txt\n",
      "250_up.txt\n",
      "251_down.txt\n",
      "251_up.txt\n",
      "254_down.txt\n",
      "254_up.txt\n",
      "263_down.txt\n",
      "263_up.txt\n",
      "264_down.txt\n",
      "264_up.txt\n",
      "275_down.txt\n",
      "275_up.txt\n",
      "276_down.txt\n",
      "276_up.txt\n",
      "280_down.txt\n",
      "280_up.txt\n",
      "281_down.txt\n",
      "281_up.txt\n",
      "282_down.txt\n",
      "282_up.txt\n",
      "292_down.txt\n",
      "292_up.txt\n",
      "304_down.txt\n",
      "304_up.txt\n",
      "305_down.txt\n",
      "305_up.txt\n",
      "307_down.txt\n",
      "307_up.txt\n",
      "314_down.txt\n",
      "314_up.txt\n"
     ]
    }
   ],
   "source": [
    "with open('templates/mm10_gallery.html', 'r') as html:    \n",
    "    for line in html:\n",
    "        search = re.findall(genelist_match, line)\n",
    "        if not search is None:\n",
    "            for genelist in search:\n",
    "                print(genelist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4_down.txt', 'down'), ('4_up.txt', 'up')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(genelist_match, test_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_gallery_metadata(species):\n",
    "    \n",
    "    with open('templates/{}_gallery.html'.format(species), 'r') as f:    \n",
    "        soup = bs4.BeautifulSoup(f.read(), 'html.parser')\n",
    "\n",
    "    headers = [x.get_text() for x in soup.find_all('th')]\n",
    "\n",
    "    def get_id(link_text):\n",
    "        search = re.search(\"filename *= *'(\\d+)_(up|down).txt'\", link_text)\n",
    "        if not search is None:\n",
    "            return search.groups()[0]\n",
    "\n",
    "\n",
    "    title_map = dict(\n",
    "        cell_type = 'Cell Type',\n",
    "        geo_id = 'GEO ID',\n",
    "        hs_gene_symbol = 'Factor Perturbed',\n",
    "        organism = 'Organism',\n",
    "        pert_type = 'Perturbation Type',\n",
    "    )\n",
    "\n",
    "    all_metadata = []\n",
    "    for row in soup.find_all('tr')[1:]:\n",
    "        metadata = dict()\n",
    "        for data, header in zip(row.find_all('td'), headers):\n",
    "            if header == 'gene_set_type':\n",
    "                metadata['id'] = dict(text = get_id(data.find_all('a')[0].get('href')), link = None)\n",
    "            elif not header == 'Combined':\n",
    "                try:\n",
    "                    link = data.find_all('a')[0].get('href')\n",
    "                except IndexError:\n",
    "                    link = None\n",
    "                metadata[title_map[header]] = dict(text = data.get_text(), link = link)\n",
    "\n",
    "        all_metadata.append(metadata)\n",
    "\n",
    "\n",
    "    with open(os.path.join('..','metadata', species + '_gallery_metadata.json'),'w') as f:\n",
    "        print(json.dumps(all_metadata), file = f)\n",
    "        \n",
    "    return all_metadata\n",
    "        \n",
    "hg38_metadata = extract_gallery_metadata('hg38')\n",
    "mm10_metadata = extract_gallery_metadata('mm10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mm10_gallery_example_292\n"
     ]
    }
   ],
   "source": [
    "def rename_gallery_files(species, metadata):\n",
    "    \n",
    "    for example in metadata:\n",
    "        \n",
    "        task_id = species + '_gallery_example_' + example['id']['text']\n",
    "        task_dir = os.path.join('..','results',task_id)\n",
    "        \n",
    "        if os.path.isdir(task_dir):\n",
    "            \n",
    "            try:\n",
    "            \n",
    "                for direction, new_prefix in zip(['up','down'],\n",
    "                        [example['Factor Perturbed']['text'] + '_Up-regulated', example['Factor Perturbed']['text'] + '_Down-regulated']):\n",
    "\n",
    "                    prefix = example['id']['text'] + '_' + direction + '.txt'\n",
    "\n",
    "                    for suffix in ['.lisa.tsv','.metadata.json']:\n",
    "\n",
    "                        _from = os.path.join(task_dir, prefix + suffix)\n",
    "                        _to = os.path.join(task_dir, new_prefix + suffix)                        \n",
    "\n",
    "                        if not os.path.isfile(_to):\n",
    "\n",
    "                            os.rename(\n",
    "                                os.path.join(task_dir, prefix + suffix), \n",
    "                                os.path.join(task_dir, new_prefix + suffix)\n",
    "                            )\n",
    "\n",
    "\n",
    "                    _to = os.path.join(task_dir, new_prefix)\n",
    "                    if not os.path.isfile(_to):\n",
    "\n",
    "                        os.rename(os.path.join('..',species + '_genelists', prefix), \n",
    "                              _to)\n",
    "                        \n",
    "            except FileNotFoundError:\n",
    "                \n",
    "                print(task_id)\n",
    "                \n",
    "\n",
    "rename_gallery_files('mm10', mm10_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioenv",
   "language": "python",
   "name": "bioenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
